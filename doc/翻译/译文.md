#### 属性

> 像广度优先搜索，完整的 A\*，在存在 `d(x,y) > ε > 0` 且 `ε` 值固定时，总能找到一个解。

> 如果启发式函数 `h` 是可接受的(注："admissibel")，则它永远不会高于到达目标的实际最低成本(注："cost")，如果我们不用 closed 集，那么 A* 本身是可接受的(或最优的)。如果使用 closed 集，那么 h 必须是单调(或一致性)才能使 A*最优。即任何一对相邻节点 x 和 y，其中 `d(x,y)`表示两点之间的长度，都必须有 `h(x) <= d(x,y) + h(y)`

> 这确保任意路径 X 从初始点到 x：
> `L(X) + h(x) <= L(X) + d(x,y) + h(y) = L(Y) + h(y)` 其中 L 是一个表示路径长度的函数，Y 是路径 X 包含 y 的扩展。换句话说，通过扩展包含相邻节点的路径来减小（目前总距离 + 估计的剩余距离）是不可能的。（这类似于 Dijkstra 算法中的非负边权重）当任何目标节点本身启发式估计为零时单调意味着可接受的，因为（假设 `P=(f,v1,v2,...,Vn,g)` 是任意节点 f 到最近的目标节点 g 的最短路径）：

> `h(f) <= d(f,v1) + h(v1) <= d(f,v1) + d(v1+v2) + h(v2) <= ... <= L(P) + h(g) = L(P)`

> 对于任何启发式 h,A\* 也是最优的，这意味着没有更优算法能在采用相同的启发式时比 A\*查找更少的点，除非在`h`能恰好预测最优路径的 cost 情况下有多个局部解决办法。即使在这种情况下，在优先级队列中每个图都存在一些断开连接的次序，使得 A\*检查尽最少的可能点。

### 特殊情况

Dijkstra 算法，一个典型的 uniform-cost 搜索算法，可以看做 A\*中 `h(x)=0` x 为所有值时的一个特例。通常深度优先搜索通过假设一个全局计数器 C 和初始化一个非常大的值来使用 A\*来实现。每次我们处理一个节点时，我们都将 C 分配给所有新的临近节点。每次单赋值之后，将计数器 C 减 1。因此，越早被发现的节点，`h(x)`值越大。Dijkstra 算法和深度优先搜索算法都能够在每个节点不包含 h(x)时更高效地实现。

### 实施细节

> 有许多简单的优化或实施细节能显著地影响 A\*的性能。首先需要注意的细节就是，优先级队列处理关系的方式会对性能在某些情况下产生显著的影响。如果关系被破坏会导致队列以 LIFO(注：后进先出)运行，A\*在等值的 cost 路径之间会采用深度优先搜索（避免探寻多个同优的解决方案）。

> 当一条路径搜索结束时，通常要保存每个节点作为父节点的参照。在搜索结束时，可以用这些参照重新获取最佳路径）。如果这些参照被保留，重要的是同一个节点不会多次出现在优先级队列中（每一项对应于节点不同的路径，且 cost 不同）。这里的标准方法是检查即将添加的节点是否已经出现在优先级队列中。如果成立，则优先级和父指针将更改为对应较低成本的路径。一个基于优先队列的标准二进制堆不对元素中的搜索操作直接支持，但可以用它扩展哈希表将元素映射到他们在堆中的位置，从而使得在对数时间内执行优先级降低操作。或者，一个斐波那契堆能够在常量平摊时间执行相同的减少优先级操作。

### 可接受性和最优性

A\* 是可接受性的并且在启发式相同时比其他任何可接受性搜索算法考虑更少的节点。这是因为 A\*对每条路径上中的每个节点用一种“乐观”估计，乐观地考虑一条路径通过节点到达目标的真实 cost 至少和估计的一样大。但是，至关重要的是，就 A\*而言，乐观估计可能是可以实现的。

> 为了证明 A\*的可接受性，使用如下算法返回的解决路径：

> 当 A\*结束搜索时，它能找出一条路径，这条路径的实际成本低于任何通过开放节点的估计成本路径。但是这些估计都是乐观的，A\*可以放心地忽略这些节点。换句话说，A\*永远不会忽视低成本路径的可能性，因此它是可接受的。

> 假设现在其他算法 B 终止搜索一条路径，这条路径实际成本不低于估计成本中通过一些开放节点的路径。根据它本身所有的启发式信息，算法 B 不能排除通过该节点的路径成本更低的可能性。因此当 B 可能比 A\*考虑更少的节点时，它一定不是可接受性的。相应的，A\*比任何其他可接受性算法能够考虑更少的节点。

> 这只有在以下情况下才成立：

* A\*使用可接受性启发式。另外，A\*不能保证比其他任何有同样启发式的搜索算法花费更少的点。
* A\*只是解决一个搜索问题而不是一系列类似的搜索问题。否则，A\*没法保证比增量启发式算法花费更少的节点。

限制松弛：

> 虽然可接受性标准能保证了一条最佳解决路径，但这也意味着 A\*必须检查所有同样有价值的路径以找到最佳路径。为了计算近似最短路径，可以通过放宽可接受性标准来以最优性为代价加速搜索。通常我们想限制这种松弛，这样可以保证求解路径不会比（1 + ε）倍最佳路径的解差。这个新的保证被称为 ε 可接受性。

有许多可接受性的算法：

* 加权 A\*/静态加权。如果`ha(n)`是可容许的启发式函数，则在 A\*搜索的加权版本中使用`hw(n)=εha(n)，ε>1`作为启发式函数，并且同之前一样执行 A\* 搜索（由于花费较少的节点，最终会比使用 ha 更快）。搜索找到的路径算法的成本至多是图中最小成本路径的成本 ε 倍。

* 动态加权使用成本函数 f(n)=g(n)+(1+εw(n))h(n),其中,<公式> ，且`d(n)`是搜索深度,N 是预期途径。

* 采用动态加权进行节点采样能更好地估计和消除启发式错误。

* 使用
